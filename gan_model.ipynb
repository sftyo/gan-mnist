{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating the Discriminator \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid() # real or fake\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "    \n",
    "### Creating the Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_dim, z_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, img_dim), # outputted a 28 x 28 x 1 -> 784\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:44<00:00, 220637.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 114774.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:06<00:00, 272652.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 931247.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 3e-4\n",
    "z_dim = 64\n",
    "image_dim = 28 * 28 * 1\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "\n",
    "disc = Discriminator(image_dim).to(device)\n",
    "gen = Generator(image_dim, z_dim).to(device)\n",
    "fixed_noise = torch.rand((batch_size, z_dim)).to(device)\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Datasets\n",
    "dataset = datasets.MNIST(root='./data',\n",
    "                         transform=transforms,\n",
    "                         download=True)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Optimizer\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0.0, loss gen 0.67, loss disc 0.60 (step : 0.0 )\n",
      "epoch 0.0, loss gen 1.70, loss disc 0.22 (step : 600.0 )\n",
      "epoch 0.0, loss gen 1.00, loss disc 0.48 (step : 1200.0 )\n",
      "epoch 0.0, loss gen 1.40, loss disc 0.36 (step : 1800.0 )\n",
      "epoch 1.0, loss gen 0.82, loss disc 0.63 (step : 0.0 )\n",
      "epoch 1.0, loss gen 1.25, loss disc 0.34 (step : 600.0 )\n",
      "epoch 1.0, loss gen 0.99, loss disc 0.66 (step : 1200.0 )\n",
      "epoch 1.0, loss gen 0.83, loss disc 0.54 (step : 1800.0 )\n",
      "epoch 2.0, loss gen 0.82, loss disc 0.62 (step : 0.0 )\n",
      "epoch 2.0, loss gen 1.18, loss disc 0.50 (step : 600.0 )\n",
      "epoch 2.0, loss gen 0.85, loss disc 0.74 (step : 1200.0 )\n",
      "epoch 2.0, loss gen 0.59, loss disc 1.00 (step : 1800.0 )\n",
      "epoch 3.0, loss gen 1.04, loss disc 0.43 (step : 0.0 )\n",
      "epoch 3.0, loss gen 0.85, loss disc 0.67 (step : 600.0 )\n",
      "epoch 3.0, loss gen 1.35, loss disc 0.62 (step : 1200.0 )\n",
      "epoch 3.0, loss gen 0.82, loss disc 0.58 (step : 1800.0 )\n",
      "epoch 4.0, loss gen 1.02, loss disc 0.56 (step : 0.0 )\n",
      "epoch 4.0, loss gen 1.28, loss disc 0.37 (step : 600.0 )\n",
      "epoch 4.0, loss gen 0.77, loss disc 0.64 (step : 1200.0 )\n",
      "epoch 4.0, loss gen 1.35, loss disc 0.59 (step : 1800.0 )\n",
      "epoch 5.0, loss gen 1.20, loss disc 0.61 (step : 0.0 )\n",
      "epoch 5.0, loss gen 1.18, loss disc 0.54 (step : 600.0 )\n",
      "epoch 5.0, loss gen 1.34, loss disc 0.41 (step : 1200.0 )\n",
      "epoch 5.0, loss gen 1.25, loss disc 0.61 (step : 1800.0 )\n",
      "epoch 6.0, loss gen 1.73, loss disc 0.32 (step : 0.0 )\n",
      "epoch 6.0, loss gen 1.29, loss disc 0.46 (step : 600.0 )\n",
      "epoch 6.0, loss gen 0.57, loss disc 0.92 (step : 1200.0 )\n",
      "epoch 6.0, loss gen 1.03, loss disc 0.62 (step : 1800.0 )\n",
      "epoch 7.0, loss gen 1.20, loss disc 0.51 (step : 0.0 )\n",
      "epoch 7.0, loss gen 0.83, loss disc 0.78 (step : 600.0 )\n",
      "epoch 7.0, loss gen 0.80, loss disc 0.89 (step : 1200.0 )\n",
      "epoch 7.0, loss gen 1.43, loss disc 0.59 (step : 1800.0 )\n",
      "epoch 8.0, loss gen 0.98, loss disc 0.90 (step : 0.0 )\n",
      "epoch 8.0, loss gen 0.87, loss disc 0.85 (step : 600.0 )\n",
      "epoch 8.0, loss gen 0.94, loss disc 0.67 (step : 1200.0 )\n",
      "epoch 8.0, loss gen 1.04, loss disc 0.48 (step : 1800.0 )\n",
      "epoch 9.0, loss gen 0.83, loss disc 0.60 (step : 0.0 )\n",
      "epoch 9.0, loss gen 1.69, loss disc 0.37 (step : 600.0 )\n",
      "epoch 9.0, loss gen 0.95, loss disc 0.57 (step : 1200.0 )\n",
      "epoch 9.0, loss gen 0.89, loss disc 0.86 (step : 1800.0 )\n",
      "epoch 10.0, loss gen 1.33, loss disc 0.52 (step : 0.0 )\n",
      "epoch 10.0, loss gen 0.80, loss disc 0.68 (step : 600.0 )\n",
      "epoch 10.0, loss gen 1.49, loss disc 0.40 (step : 1200.0 )\n",
      "epoch 10.0, loss gen 0.86, loss disc 0.79 (step : 1800.0 )\n",
      "epoch 11.0, loss gen 1.09, loss disc 0.69 (step : 0.0 )\n",
      "epoch 11.0, loss gen 1.32, loss disc 0.44 (step : 600.0 )\n",
      "epoch 11.0, loss gen 0.99, loss disc 0.66 (step : 1200.0 )\n",
      "epoch 11.0, loss gen 1.02, loss disc 0.56 (step : 1800.0 )\n",
      "epoch 12.0, loss gen 1.00, loss disc 0.65 (step : 0.0 )\n",
      "epoch 12.0, loss gen 0.70, loss disc 0.75 (step : 600.0 )\n",
      "epoch 12.0, loss gen 0.97, loss disc 0.57 (step : 1200.0 )\n",
      "epoch 12.0, loss gen 0.97, loss disc 0.83 (step : 1800.0 )\n",
      "epoch 13.0, loss gen 0.93, loss disc 0.60 (step : 0.0 )\n",
      "epoch 13.0, loss gen 0.92, loss disc 0.65 (step : 600.0 )\n",
      "epoch 13.0, loss gen 1.07, loss disc 0.50 (step : 1200.0 )\n",
      "epoch 13.0, loss gen 1.15, loss disc 0.46 (step : 1800.0 )\n",
      "epoch 14.0, loss gen 1.13, loss disc 0.57 (step : 0.0 )\n",
      "epoch 14.0, loss gen 0.75, loss disc 0.92 (step : 600.0 )\n",
      "epoch 14.0, loss gen 1.02, loss disc 0.61 (step : 1200.0 )\n",
      "epoch 14.0, loss gen 0.86, loss disc 0.82 (step : 1800.0 )\n",
      "epoch 15.0, loss gen 1.13, loss disc 0.71 (step : 0.0 )\n",
      "epoch 15.0, loss gen 0.95, loss disc 0.72 (step : 600.0 )\n",
      "epoch 15.0, loss gen 1.00, loss disc 0.63 (step : 1200.0 )\n",
      "epoch 15.0, loss gen 0.83, loss disc 0.64 (step : 1800.0 )\n",
      "epoch 16.0, loss gen 0.93, loss disc 0.59 (step : 0.0 )\n",
      "epoch 16.0, loss gen 1.30, loss disc 0.54 (step : 600.0 )\n",
      "epoch 16.0, loss gen 0.73, loss disc 0.82 (step : 1200.0 )\n",
      "epoch 16.0, loss gen 1.05, loss disc 0.49 (step : 1800.0 )\n",
      "epoch 17.0, loss gen 0.88, loss disc 0.61 (step : 0.0 )\n",
      "epoch 17.0, loss gen 0.85, loss disc 0.70 (step : 600.0 )\n",
      "epoch 17.0, loss gen 0.91, loss disc 0.68 (step : 1200.0 )\n",
      "epoch 17.0, loss gen 1.08, loss disc 0.59 (step : 1800.0 )\n",
      "epoch 18.0, loss gen 0.83, loss disc 0.72 (step : 0.0 )\n",
      "epoch 18.0, loss gen 1.13, loss disc 0.67 (step : 600.0 )\n",
      "epoch 18.0, loss gen 1.16, loss disc 0.59 (step : 1200.0 )\n",
      "epoch 18.0, loss gen 1.23, loss disc 0.48 (step : 1800.0 )\n",
      "epoch 19.0, loss gen 1.03, loss disc 0.59 (step : 0.0 )\n",
      "epoch 19.0, loss gen 0.89, loss disc 0.62 (step : 600.0 )\n",
      "epoch 19.0, loss gen 0.86, loss disc 0.62 (step : 1200.0 )\n",
      "epoch 19.0, loss gen 0.98, loss disc 0.59 (step : 1800.0 )\n",
      "epoch 20.0, loss gen 1.21, loss disc 0.59 (step : 0.0 )\n",
      "epoch 20.0, loss gen 0.98, loss disc 0.70 (step : 600.0 )\n",
      "epoch 20.0, loss gen 0.92, loss disc 0.60 (step : 1200.0 )\n",
      "epoch 20.0, loss gen 0.82, loss disc 0.67 (step : 1800.0 )\n",
      "epoch 21.0, loss gen 0.85, loss disc 0.64 (step : 0.0 )\n",
      "epoch 21.0, loss gen 1.14, loss disc 0.60 (step : 600.0 )\n",
      "epoch 21.0, loss gen 0.98, loss disc 0.61 (step : 1200.0 )\n",
      "epoch 21.0, loss gen 0.82, loss disc 0.76 (step : 1800.0 )\n",
      "epoch 22.0, loss gen 1.06, loss disc 0.50 (step : 0.0 )\n",
      "epoch 22.0, loss gen 0.93, loss disc 0.57 (step : 600.0 )\n",
      "epoch 22.0, loss gen 0.79, loss disc 0.75 (step : 1200.0 )\n",
      "epoch 22.0, loss gen 1.01, loss disc 0.59 (step : 1800.0 )\n",
      "epoch 23.0, loss gen 1.26, loss disc 0.70 (step : 0.0 )\n",
      "epoch 23.0, loss gen 0.98, loss disc 0.55 (step : 600.0 )\n",
      "epoch 23.0, loss gen 1.13, loss disc 0.64 (step : 1200.0 )\n",
      "epoch 23.0, loss gen 1.05, loss disc 0.59 (step : 1800.0 )\n",
      "epoch 24.0, loss gen 1.03, loss disc 0.67 (step : 0.0 )\n",
      "epoch 24.0, loss gen 1.13, loss disc 0.58 (step : 600.0 )\n",
      "epoch 24.0, loss gen 1.01, loss disc 0.70 (step : 1200.0 )\n",
      "epoch 24.0, loss gen 1.02, loss disc 0.61 (step : 1800.0 )\n",
      "epoch 25.0, loss gen 1.12, loss disc 0.65 (step : 0.0 )\n",
      "epoch 25.0, loss gen 1.38, loss disc 0.44 (step : 600.0 )\n",
      "epoch 25.0, loss gen 1.12, loss disc 0.65 (step : 1200.0 )\n",
      "epoch 25.0, loss gen 0.92, loss disc 0.61 (step : 1800.0 )\n",
      "epoch 26.0, loss gen 0.91, loss disc 0.67 (step : 0.0 )\n",
      "epoch 26.0, loss gen 0.82, loss disc 0.68 (step : 600.0 )\n",
      "epoch 26.0, loss gen 1.15, loss disc 0.61 (step : 1200.0 )\n",
      "epoch 26.0, loss gen 0.87, loss disc 0.67 (step : 1800.0 )\n",
      "epoch 27.0, loss gen 1.05, loss disc 0.63 (step : 0.0 )\n",
      "epoch 27.0, loss gen 1.26, loss disc 0.57 (step : 600.0 )\n",
      "epoch 27.0, loss gen 1.01, loss disc 0.69 (step : 1200.0 )\n",
      "epoch 27.0, loss gen 1.33, loss disc 0.60 (step : 1800.0 )\n",
      "epoch 28.0, loss gen 1.11, loss disc 0.59 (step : 0.0 )\n",
      "epoch 28.0, loss gen 1.25, loss disc 0.50 (step : 600.0 )\n",
      "epoch 28.0, loss gen 1.06, loss disc 0.59 (step : 1200.0 )\n",
      "epoch 28.0, loss gen 1.20, loss disc 0.49 (step : 1800.0 )\n",
      "epoch 29.0, loss gen 0.88, loss disc 0.68 (step : 0.0 )\n",
      "epoch 29.0, loss gen 0.67, loss disc 0.82 (step : 600.0 )\n",
      "epoch 29.0, loss gen 0.99, loss disc 0.71 (step : 1200.0 )\n",
      "epoch 29.0, loss gen 1.06, loss disc 0.66 (step : 1800.0 )\n",
      "epoch 30.0, loss gen 0.97, loss disc 0.51 (step : 0.0 )\n",
      "epoch 30.0, loss gen 1.15, loss disc 0.57 (step : 600.0 )\n",
      "epoch 30.0, loss gen 1.01, loss disc 0.66 (step : 1200.0 )\n",
      "epoch 30.0, loss gen 0.93, loss disc 0.62 (step : 1800.0 )\n",
      "epoch 31.0, loss gen 0.99, loss disc 0.69 (step : 0.0 )\n",
      "epoch 31.0, loss gen 1.11, loss disc 0.60 (step : 600.0 )\n",
      "epoch 31.0, loss gen 1.16, loss disc 0.57 (step : 1200.0 )\n",
      "epoch 31.0, loss gen 0.75, loss disc 0.76 (step : 1800.0 )\n",
      "epoch 32.0, loss gen 1.06, loss disc 0.51 (step : 0.0 )\n",
      "epoch 32.0, loss gen 1.16, loss disc 0.54 (step : 600.0 )\n",
      "epoch 32.0, loss gen 1.30, loss disc 0.53 (step : 1200.0 )\n",
      "epoch 32.0, loss gen 1.08, loss disc 0.76 (step : 1800.0 )\n",
      "epoch 33.0, loss gen 0.93, loss disc 0.59 (step : 0.0 )\n",
      "epoch 33.0, loss gen 1.02, loss disc 0.59 (step : 600.0 )\n",
      "epoch 33.0, loss gen 1.35, loss disc 0.51 (step : 1200.0 )\n",
      "epoch 33.0, loss gen 1.17, loss disc 0.63 (step : 1800.0 )\n",
      "epoch 34.0, loss gen 1.03, loss disc 0.64 (step : 0.0 )\n",
      "epoch 34.0, loss gen 0.93, loss disc 0.57 (step : 600.0 )\n",
      "epoch 34.0, loss gen 1.06, loss disc 0.68 (step : 1200.0 )\n",
      "epoch 34.0, loss gen 1.09, loss disc 0.65 (step : 1800.0 )\n",
      "epoch 35.0, loss gen 1.24, loss disc 0.65 (step : 0.0 )\n",
      "epoch 35.0, loss gen 1.11, loss disc 0.57 (step : 600.0 )\n",
      "epoch 35.0, loss gen 1.20, loss disc 0.51 (step : 1200.0 )\n",
      "epoch 35.0, loss gen 0.90, loss disc 0.68 (step : 1800.0 )\n",
      "epoch 36.0, loss gen 0.98, loss disc 0.65 (step : 0.0 )\n",
      "epoch 36.0, loss gen 1.00, loss disc 0.61 (step : 600.0 )\n",
      "epoch 36.0, loss gen 0.94, loss disc 0.72 (step : 1200.0 )\n",
      "epoch 36.0, loss gen 0.99, loss disc 0.76 (step : 1800.0 )\n",
      "epoch 37.0, loss gen 1.11, loss disc 0.59 (step : 0.0 )\n",
      "epoch 37.0, loss gen 1.16, loss disc 0.59 (step : 600.0 )\n",
      "epoch 37.0, loss gen 1.08, loss disc 0.65 (step : 1200.0 )\n",
      "epoch 37.0, loss gen 0.98, loss disc 0.68 (step : 1800.0 )\n",
      "epoch 38.0, loss gen 0.90, loss disc 0.65 (step : 0.0 )\n",
      "epoch 38.0, loss gen 1.04, loss disc 0.75 (step : 600.0 )\n",
      "epoch 38.0, loss gen 1.07, loss disc 0.59 (step : 1200.0 )\n",
      "epoch 38.0, loss gen 0.92, loss disc 0.62 (step : 1800.0 )\n",
      "epoch 39.0, loss gen 1.04, loss disc 0.66 (step : 0.0 )\n",
      "epoch 39.0, loss gen 1.01, loss disc 0.57 (step : 600.0 )\n",
      "epoch 39.0, loss gen 1.00, loss disc 0.72 (step : 1200.0 )\n",
      "epoch 39.0, loss gen 0.87, loss disc 0.53 (step : 1800.0 )\n",
      "epoch 40.0, loss gen 0.77, loss disc 0.77 (step : 0.0 )\n",
      "epoch 40.0, loss gen 0.84, loss disc 0.70 (step : 600.0 )\n",
      "epoch 40.0, loss gen 0.77, loss disc 0.82 (step : 1200.0 )\n",
      "epoch 40.0, loss gen 0.92, loss disc 0.67 (step : 1800.0 )\n",
      "epoch 41.0, loss gen 0.92, loss disc 0.62 (step : 0.0 )\n",
      "epoch 41.0, loss gen 0.90, loss disc 0.60 (step : 600.0 )\n",
      "epoch 41.0, loss gen 0.97, loss disc 0.64 (step : 1200.0 )\n",
      "epoch 41.0, loss gen 0.92, loss disc 0.67 (step : 1800.0 )\n",
      "epoch 42.0, loss gen 0.98, loss disc 0.56 (step : 0.0 )\n",
      "epoch 42.0, loss gen 0.78, loss disc 0.72 (step : 600.0 )\n",
      "epoch 42.0, loss gen 1.06, loss disc 0.63 (step : 1200.0 )\n",
      "epoch 42.0, loss gen 0.78, loss disc 0.60 (step : 1800.0 )\n",
      "epoch 43.0, loss gen 1.12, loss disc 0.66 (step : 0.0 )\n",
      "epoch 43.0, loss gen 1.10, loss disc 0.57 (step : 600.0 )\n",
      "epoch 43.0, loss gen 0.81, loss disc 0.62 (step : 1200.0 )\n",
      "epoch 43.0, loss gen 1.01, loss disc 0.57 (step : 1800.0 )\n",
      "epoch 44.0, loss gen 0.93, loss disc 0.56 (step : 0.0 )\n",
      "epoch 44.0, loss gen 0.96, loss disc 0.64 (step : 600.0 )\n",
      "epoch 44.0, loss gen 0.93, loss disc 0.59 (step : 1200.0 )\n",
      "epoch 44.0, loss gen 1.03, loss disc 0.60 (step : 1800.0 )\n",
      "epoch 45.0, loss gen 1.10, loss disc 0.59 (step : 0.0 )\n",
      "epoch 45.0, loss gen 1.04, loss disc 0.61 (step : 600.0 )\n",
      "epoch 45.0, loss gen 0.78, loss disc 0.73 (step : 1200.0 )\n",
      "epoch 45.0, loss gen 0.83, loss disc 0.69 (step : 1800.0 )\n",
      "epoch 46.0, loss gen 0.97, loss disc 0.66 (step : 0.0 )\n",
      "epoch 46.0, loss gen 0.93, loss disc 0.65 (step : 600.0 )\n",
      "epoch 46.0, loss gen 0.92, loss disc 0.64 (step : 1200.0 )\n",
      "epoch 46.0, loss gen 0.97, loss disc 0.60 (step : 1800.0 )\n",
      "epoch 47.0, loss gen 0.83, loss disc 0.70 (step : 0.0 )\n",
      "epoch 47.0, loss gen 0.96, loss disc 0.57 (step : 600.0 )\n",
      "epoch 47.0, loss gen 0.84, loss disc 0.62 (step : 1200.0 )\n",
      "epoch 47.0, loss gen 1.05, loss disc 0.61 (step : 1800.0 )\n",
      "epoch 48.0, loss gen 0.92, loss disc 0.67 (step : 0.0 )\n",
      "epoch 48.0, loss gen 0.82, loss disc 0.70 (step : 600.0 )\n",
      "epoch 48.0, loss gen 0.83, loss disc 0.69 (step : 1200.0 )\n",
      "epoch 48.0, loss gen 0.89, loss disc 0.58 (step : 1800.0 )\n",
      "epoch 49.0, loss gen 0.97, loss disc 0.61 (step : 0.0 )\n",
      "epoch 49.0, loss gen 0.77, loss disc 0.69 (step : 600.0 )\n",
      "epoch 49.0, loss gen 1.07, loss disc 0.61 (step : 1200.0 )\n",
      "epoch 49.0, loss gen 1.01, loss disc 0.65 (step : 1800.0 )\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (real, _) in enumerate(loader):\n",
    "        real = real.view(-1, 784).to(device)\n",
    "        batch_size = real.shape[0]\n",
    "        \n",
    "        ### Train a Discriminator: max log(D(real)) + log(1 - D(G(z)))\n",
    "        noise = torch.randn((batch_size,z_dim)).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).view(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "        \n",
    "        ### Train a Generator: max log(D(G(z)))\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        \n",
    "        if i % 600 == 0:\n",
    "            print('epoch %.1f, loss gen %.2f, loss disc %.2f (step : %.1f )' % (epoch, lossG, lossD, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(torch.tensor(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
